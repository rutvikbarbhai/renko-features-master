# <img src="https://github.com/user-attachments/assets/fa3efb02-55b5-4774-8a26-9aaad86acf1e" width="30"> Decision Tree Based Trade Pattern Mining Using Renko Dataset
## <img src="https://github.com/user-attachments/assets/dcdcffb4-c4e2-40ee-84cc-aca8612d257e" width="30px">Summary

This repository implements an end-to-end quantitative machine learning pipeline developed during the Xcitiumâ€“NuFintech Internship. 
The project focuses on transforming raw financial features into interpretable, statistically validated, and production-ready trading patterns using leakage-safe feature engineering, decision treeâ€“based clustering, and rigorous multi-stage validation using renko dataset . The core philosophy of this project is robustness over complexity â€” prioritizing explainability, out-of-sample reliability, and temporal stability rather than black-box performance.

## <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="30px" style="vertical-align:text-bottom;"> Repository Contents

```bash
ğŸ“ renko-features-master/
â”œâ”€â”€ ğŸ“.ipynb_checkpoints
â”‚    â”œâ”€â”€ module0_files_fetching_run_locally-checkpoint.py
â”‚    â””â”€â”€ module2_tsfresh_features_v4-checkpoint.py
â”œâ”€â”€ ğŸ“ config
â”‚    â””â”€â”€ pipeline_config.txt 
â”œâ”€â”€ ğŸ“ core
â”‚    â”œâ”€â”€ __init__.py
â”‚    â”œâ”€â”€ comparison.ipynb
â”‚    â”œâ”€â”€ db_decorators.py
â”‚    â”œâ”€â”€ logs.py
â”‚    â””â”€â”€ settings.py
â”œâ”€â”€ ğŸ“ data
â”‚    â””â”€â”€ storage.py
â”œâ”€â”€ ğŸ“ tests
â”‚    â”œâ”€â”€ __init__.py
â”‚    â””â”€â”€ test_apply_dynamic_features.py
â”œâ”€â”€ ğŸ“ modules /  
â”‚   â”‚   â”œâ”€â”€ module0_files_fetching_run_locally.py
â”‚   â”‚   â”œâ”€â”€ module1_comb_file_creation.py
â”‚   â”‚   â”œâ”€â”€ module2_tsfresh_features_v3.py
â”‚   â”‚   â”œâ”€â”€ module2_tsfresh_features_v4.py
â”‚   â”‚   â”œâ”€â”€ module3_data_preparation.py
â”‚   â”‚   â”œâ”€â”€ module4_feature_reduction.py
â”‚   â”‚   â”œâ”€â”€ module5_with_hyperparameter_tuning.py
â”‚   â”‚   â”œâ”€â”€ module6_cluster_analysis.py
â”‚   â”‚   â”œâ”€â”€ module7_rule_extraction.py
â”‚   â”‚   â”œâ”€â”€ module8_rule_analysis_and_pattern_detection.py
â”‚   â”‚   â”œâ”€â”€ module9_backtesting.py
â”‚   â”‚   â””â”€â”€ module10_walkforward.py
â”‚   â”œâ”€â”€ .flake8
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ config.json
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ tsfresh_features.py
â””â”€â”€ ğŸ“„ README.md

```

## <img src="https://github.com/user-attachments/assets/f03f321f-8340-452b-b82a-33f487bb52a4" width="28" style="vertical-align: text-bottom;"/> MODULE 1: FEATURE ENGINEERING & SELECTION

### <img src="https://github.com/user-attachments/assets/6672ee8c-15ed-4fb5-9cd5-63c04ac747c1" height="20px" style="vertical-align:bottom;"> Working:
Four-stage feature reduction process applied to prevent data leakage and optimize model performance:  

- 1ï¸âƒ£ Analyzed **190 raw features** for redundancy via correlation analysis, low-variance detection, and one-hot group identification.
- 2ï¸âƒ£ Performed **80/20 stratified train-test split BEFORE any feature engineering** to ensure zero information leakage, created target-encoded features using only training data statistics.
- 3ï¸âƒ£ Reduced features from **81 to 50** through time-window consolidation (kept 5d, dropped other variants), domain-based filtering with Random Forest importance verification, and final importance-based ranking.
- 4ï¸âƒ£ Validated that feature reduction maintained test performance while reducing overfitting.

### ğŸ“¦ Output Files:

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 1.1a (Feature Cleanup Analysis):
- `features_to_drop.txt`  â€“ List of redundant features identified for removal.  
- `cleaned_features.txt`  â€“ Initial cleaned feature list after redundancy removal.  
- `feature_analysis_report.json`  â€“ Detailed redundancy analysis with correlation and variance statistics.  

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 1.1b (Dataset Preparation):
- `train_prepared.parquet` â€“ Training dataset with **13,600 samples** and engineered features.  
- `test_prepared.parquet`  â€“ Test dataset with **3,400 samples** using same transformations.  
- `prepared_features.txt`  â€“ List of **81 features** after cleanup and encoding.  
- `feature_engineering_artifacts.json`  â€“ Target encoding maps learned from training data only.  
- `dataset_summary.json` â€“ Train/test split statistics and class distributions.  

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 1.2 (Feature Reduction):
- `final_features.txt` â€“ Final **50 optimized features** selected for modeling.  
- `reduction_summary.json`  â€“ Step-by-step reduction statistics showing **81 â†’ 50** feature reduction.  

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 1.3 (Feature Validation):
- `validation_comparison.png`  â€“ Train vs test accuracy comparison chart demonstrating overfitting reduction.  
- `performance_comparison.csv` â€“ Detailed metrics including train accuracy, test accuracy, and overfitting gap comparison.  



## <img src="https://github.com/user-attachments/assets/8f09f616-c687-48a1-8a30-76dffda656b9" width="28" style="position: relative; top: 3px;"/> MODULE 2: MODEL TRAINING (DECISION TREE CLUSTERING)

### <img src="https://github.com/user-attachments/assets/6672ee8c-15ed-4fb5-9cd5-63c04ac747c1" height="20px" style="vertical-align:bottom;"> Working:
Trained decision tree classifier on **50 optimized features** using training data only with hyperparameters:  
`max_depth=10`, `min_samples_split=30`, `min_samples_leaf=20`.  
resulting in **195 leaf nodes** where each leaf represents a distinct pattern cluster defined by specific feature threshold conditions from root to leaf.

### ğŸ“¦ Output Files:
- `decision_tree_model.pkl` â€“ Trained decision tree model with **195 leaf nodes**  
- `model_metadata.json` â€“ Model hyperparameters, tree depth, number of leaves, and feature names.  
- `cluster_rules.json`  â€“ Complete path conditions from root to each leaf for all **195 clusters**  
- `decision_tree.png`   â€“ Tree visualization showing top 3 levels of split logic.  
- `confusion_matrix.png`  â€“ Test set performance visualization.  
- `feature_importance.png` â€“ Bar chart of top 15 most important features for splitting decisions.  



## <img src="https://github.com/user-attachments/assets/39198c0b-6b23-4755-9fe9-86135085a06b" width="28" style="position: relative; top: 3px;"/> MODULE 3: CLUSTER ANALYSIS & QUALITY FILTERING

### <img src="https://github.com/user-attachments/assets/6672ee8c-15ed-4fb5-9cd5-63c04ac747c1" height="20px" style="vertical-align:bottom;"> Working:
Analyzed all **195 decision tree leaf node clusters** on combined train and test data, calculated cluster purity (dominant class percentage), size, and top 5 distinguishing features per cluster, then applied actionable criteria filtering for **purity â‰¥70%** and **size â‰¥50 samples** to identify high-quality patterns, resulting in **42 actionable clusters** meeting quality thresholds.

### ğŸ“¦ Output Files:
- `cluster_statistics.json`  â€“ Complete statistics for all **195 clusters** including size, purity, target distribution, and top 5 distinguishing features with percentage differences from global means.  
- `actionable_clusters.json` â€“ **42 patterns** meeting quality criteria with cluster ID, size, purity, dominant class, and confidence score.  
- `cluster_distribution.png` â€“ Four-panel visualization showing cluster sizes, target distribution by cluster, purity histogram, and size distribution.  



## <img src="https://github.com/user-attachments/assets/da81abd6-53fd-49a0-814f-d2b8d0062730" width="28" style="position: relative; top: 3px;"/> MODULE 4: RULE EXTRACTION & ANALYSIS


### <img src="https://github.com/user-attachments/assets/6672ee8c-15ed-4fb5-9cd5-63c04ac747c1" height="20px" style="vertical-align:bottom;">  Working:
Extracted interpretable decision rules by tracing root-to-leaf paths for **42 actionable clusters**, converting tree split conditions into readable if-then rules, organized rules into **3 confidence tiers** based on purity.  
(Tier 1: â‰¥95%, Tier 2: 85â€“95%, Tier 3: 70â€“85%),

Calculated signal strength scores (0â€“10) based on confidence and sample size, then analyzed patterns across rules to identify most important features, common feature combinations, signal direction balance, and potential rule conflicts.

### ğŸ“¦ Output Files:

### <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 4.1 (Rule Extraction):

- `rule_catalog.json` â€“ All **42 extracted rules** with full conditions, tier assignments, confidence scores, signal strength, and predicted classes.  
- `rules_summary.csv` â€“ Tabular summary with cluster ID, signal direction, confidence percentage, sample size, strength score, and condition count.  
- `rules_detailed.txt`â€“ Human-readable format with complete conditions and trading interpretations for all **42 rules**.  
- `rules_quick_reference.txt` â€“ Condensed trading desk guide showing only **Tier 1 rules (â‰¥95% confidence)**.  

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 4.2 (Rule Analysis & Pattern Detection):
- `feature_importance_analysis.png`  â€“ Dual-panel chart showing overall feature frequency and tier-based breakdown.  
- `rule_analysis.json` â€“ Comprehensive analysis data including feature frequencies by tier, signal direction statistics, top features by direction, and identified conflicts.  
- `key_insights.txt`   â€“ Actionable summary with top 5 critical features, signal bias assessment, and improvement recommendations.  



## <img src="https://github.com/user-attachments/assets/6467a42f-afae-4dc7-8ede-46f12a087c6f" width="20" /> MODULE 5: PATTERN VALIDATION (BACKTESTING & WALK-FORWARD)

### <img src="https://github.com/user-attachments/assets/6672ee8c-15ed-4fb5-9cd5-63c04ac747c1" height="20px" style="vertical-align:bottom;">  Working:
Applied rigorous multi-period validation to **42 actionable patterns** through three stages:  

- 1ï¸âƒ£ Backtest validation on **20% held-out test set** measuring out-of-sample accuracy per cluster.  
- 2ï¸âƒ£ Walk-forward validation testing each pattern across **5 independent time periods** to assess temporal stability via mean accuracy, standard deviation, and coefficient of variation. 
- 3ï¸âƒ£ Comprehensive quality analysis calculating reliability scores (0â€“100) based on sample size adequacy, stability, accuracy consistency, and train-test degradation, then filtering for patterns with **reliability â‰¥70** and no critical issues, resulting in **16 production-quality patterns**.

### ğŸ“¦ Output Files:

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 5.1 (Backtesting):
- `cluster_performance.csv` â€“ Per-cluster test set accuracy, sample counts, true positives, false positives, true negatives, false negatives.  
- `backtest_summary.json`  â€“ Overall performance statistics across all **42 patterns**.  

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 5.2 (Walk-Forward Validation):
- `walkforward_stability.csv`  â€“ Stability metrics per pattern: mean accuracy across 5 periods, standard deviation, coefficient of variation, minimum and maximum accuracy.  
- `walkforward_results_detailed.csv`  â€“ Individual period performance showing accuracy in each of the **5 time windows** per pattern.  
- `walkforward_degrading.csv`  â€“ Patterns showing significant performance degradation over time periods.  
- `stability_analysis.png`  â€“ Visualization of pattern consistency across validation periods.  

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;">  Module 5.3 (Quality Analysis & Final Filtering):
- `pattern_quality_analysis.csv`  â€“ All **42 patterns** with quality grades (A+ to F), reliability scores, tier assignments, accuracy metrics, stability CV, test sample counts, degradation percentages, and flagged issues.  
- `usable_patterns_only.csv`  â€“ **16 patterns** passing final criteria (reliability â‰¥70, issues=CLEAN) ready for consideration. 
- `grade_a_patterns.csv`  â€“ **14 highest-quality patterns** graded A+ or A representing **87.5% of validated set**.


